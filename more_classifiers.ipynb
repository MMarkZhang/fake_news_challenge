{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from utils import * \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ferguson riots: Pregnant woman loses eye after...</td>\n",
       "      <td>2008</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>A RESPECTED senior French police officer inves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crazy Conservatives Are Sure a Gitmo Detainee ...</td>\n",
       "      <td>1550</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>Dave Morin's social networking company Path is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Russian Guy Says His Justin Bieber Ringtone ...</td>\n",
       "      <td>2</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>A bereaved Afghan mother took revenge on the T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zombie Cat: Buried Kitty Believed Dead, Meows ...</td>\n",
       "      <td>1793</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>Hewlett-Packard is officially splitting in two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina's President Adopts Boy to End Werewo...</td>\n",
       "      <td>37</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>An airline passenger headed to Dallas was remo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance  \\\n",
       "0  Ferguson riots: Pregnant woman loses eye after...     2008  unrelated   \n",
       "1  Crazy Conservatives Are Sure a Gitmo Detainee ...     1550  unrelated   \n",
       "2  A Russian Guy Says His Justin Bieber Ringtone ...        2  unrelated   \n",
       "3  Zombie Cat: Buried Kitty Believed Dead, Meows ...     1793  unrelated   \n",
       "4  Argentina's President Adopts Boy to End Werewo...       37  unrelated   \n",
       "\n",
       "                                         articleBody  \n",
       "0  A RESPECTED senior French police officer inves...  \n",
       "1  Dave Morin's social networking company Path is...  \n",
       "2  A bereaved Afghan mother took revenge on the T...  \n",
       "3  Hewlett-Packard is officially splitting in two...  \n",
       "4  An airline passenger headed to Dallas was remo...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies = pd.read_csv('./data/train_bodies.csv')\n",
    "train = pd.read_csv('./data/train_stances.csv')\n",
    "\n",
    "df_train = train.merge(train_bodies, on=['Body ID'], how='left')\n",
    "df_train.head()\n",
    "\n",
    "test_bodies = pd.read_csv('./data/competition_test_bodies.csv')\n",
    "test = pd.read_csv('./data/competition_test_stances.csv')\n",
    "\n",
    "df_test = test.merge(test_bodies, on=['Body ID'], how='left')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40350, 4)\n",
      "(9622, 4)\n",
      "(49972, 4)\n"
     ]
    }
   ],
   "source": [
    "train_ids = [int(v) for v in open('./data/training_ids.txt').read().strip().split('\\n')]\n",
    "val_ids = [int(v) for v in open('./data/hold_out_ids.txt').read().strip().split('\\n')]\n",
    "        \n",
    "df_train_a = df_train[df_train['Body ID'].isin(train_ids)]\n",
    "df_train_b = df_train[df_train['Body ID'].isin(val_ids)]\n",
    "print(df_train_a.shape)\n",
    "print(df_train_b.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train a tfidf and serialize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenize.word_tokenize, max_df=0.8, min_df=5, max_features=10000, sublinear_tf=True, ngram_range=(1,3))\n",
    "tfidf.fit(df_train['Headline'].tolist() + df_train['articleBody'].tolist() + df_test['Headline'].tolist() + df_test['articleBody'].tolist())\n",
    "joblib.dump(tfidf, './tmp/tfidf_gram_1_3.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = joblib.load('./tmp/tfidf_gram_1_3.pkl')\n",
    "train_headline = tfidf.transform(df_train_a['Headline'].tolist())\n",
    "train_body = tfidf.transform(df_train_a['articleBody'].tolist())\n",
    "\n",
    "val_headline = tfidf.transform(df_train_b['Headline'].tolist())\n",
    "val_body = tfidf.transform(df_train_b['articleBody'].tolist())\n",
    "\n",
    "test_headline = tfidf.transform(df_test['Headline'].tolist())\n",
    "test_body = tfidf.transform(df_test['articleBody'].tolist())\n",
    "\n",
    "data = {'train_headline': train_headline, 'train_body':train_body, 'val_headline': val_headline, 'val_body': val_body, \n",
    "       'test_headline': test_headline, 'test_body': test_body}\n",
    "pickle.dump(data, open('./tmp/headline_body_tfidf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pickle.load(open('./tmp/headline_body_tfidf.pkl', 'rb'))\n",
    "train_headline = data['train_headline']\n",
    "train_body = data['train_body']\n",
    "\n",
    "val_headline = data['val_headline']\n",
    "val_body = data['val_body']\n",
    "\n",
    "test_headline = data['test_headline']\n",
    "test_body = data['test_body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map y from string to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_2_id = {'agree': 0, 'disagree': 1, 'discuss':2, 'unrelated': 3}\n",
    "train_stance = df_train_a['Stance'].map(lambda x: label_2_id[x]).tolist()\n",
    "val_stance = df_train_b['Stance'].map(lambda x: label_2_id[x]).tolist()\n",
    "test_stance = df_test['Stance'].map(lambda x: label_2_id[x]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calcuate tfidf similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def get_sim_score(a, b):\n",
    "    assert a.shape == b.shape\n",
    "    res = []\n",
    "    for row in range(a.shape[0]):\n",
    "        cos = cosine_similarity(a[row], b[row])[0, 0]\n",
    "        res.append(cos)\n",
    "    return np.array(res).reshape(-1, 1)\n",
    "\n",
    "train_sim = get_sim_score(train_headline, train_body)\n",
    "val_sim = get_sim_score(val_headline, val_body)\n",
    "test_sim = get_sim_score(test_headline, test_body)\n",
    "\n",
    "tfidf_sim = {'train_sim': train_sim, 'val_sim': val_sim, 'test_sim': test_sim}\n",
    "pickle.dump(tfidf_sim, open('./tmp/tfidf_sim.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_sim = pickle.load(open('./tmp/tfidf_sim.pkl', 'rb'))\n",
    "train_sim = tfidf_sim['train_sim']\n",
    "val_sim = tfidf_sim['val_sim']\n",
    "test_sim = tfidf_sim['test_sim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = hstack((train_headline, train_body, train_sim))\n",
    "y_train = np.array(train_stance)\n",
    "\n",
    "X_val = hstack((val_headline, val_body, val_sim))\n",
    "y_val = np.array(val_stance)\n",
    "\n",
    "X_test = hstack((test_headline, test_body, test_sim))\n",
    "y_test = np.array(test_stance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate on the val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.58      0.65       762\n",
      "          1       0.59      0.31      0.41       162\n",
      "          2       0.80      0.84      0.82      1800\n",
      "          3       0.97      0.99      0.98      6898\n",
      "\n",
      "avg / total       0.91      0.92      0.91      9622\n",
      "\n",
      "accuracy: 0.916\n",
      "macro f1: 0.715\n",
      "score: 0.862\n",
      "--------------------------------------------------\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.48      0.59       762\n",
      "          1       0.64      0.14      0.23       162\n",
      "          2       0.79      0.82      0.81      1800\n",
      "          3       0.95      0.99      0.97      6898\n",
      "\n",
      "avg / total       0.90      0.91      0.90      9622\n",
      "\n",
      "accuracy: 0.907\n",
      "macro f1: 0.649\n",
      "score: 0.833\n",
      "--------------------------------------------------\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.14      0.19       762\n",
      "          1       0.00      0.00      0.00       162\n",
      "          2       0.43      0.52      0.47      1800\n",
      "          3       0.79      0.82      0.81      6898\n",
      "\n",
      "avg / total       0.67      0.70      0.68      9622\n",
      "\n",
      "accuracy: 0.695\n",
      "macro f1: 0.367\n",
      "score: 0.562\n",
      "--------------------------------------------------\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 4), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=10, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.64      0.63       762\n",
      "          1       0.62      0.28      0.38       162\n",
      "          2       0.76      0.88      0.82      1800\n",
      "          3       0.99      0.96      0.97      6898\n",
      "\n",
      "avg / total       0.91      0.91      0.91      9622\n",
      "\n",
      "accuracy: 0.906\n",
      "macro f1: 0.701\n",
      "score: 0.875\n"
     ]
    }
   ],
   "source": [
    "clfs = [LinearSVC(), LogisticRegression(), MultinomialNB(), MLPClassifier(hidden_layer_sizes=(100, 4), early_stopping=True, max_iter=10)]\n",
    "\n",
    "for clf in clfs:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    \n",
    "    print('-' * 50)\n",
    "    print(clf)\n",
    "    print('classification report:')\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print('accuracy: %.3f' % accuracy_score(y_val, y_pred))\n",
    "    print('macro f1: %.3f' % f1_score(y_val, y_pred, average='macro'))\n",
    "    print('score: %.3f' % (get_score(y_val, y_pred) / get_score(y_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add RandomForest and LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50building tree 2 of 50building tree 3 of 50\n",
      "\n",
      "\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   18.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   30.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   42.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   58.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
      "            oob_score=False, random_state=42, verbose=10, warm_start=False)\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.41      0.46       762\n",
      "          1       0.79      0.16      0.27       162\n",
      "          2       0.72      0.77      0.74      1800\n",
      "          3       0.92      0.95      0.93      6898\n",
      "\n",
      "avg / total       0.85      0.86      0.85      9622\n",
      "\n",
      "accuracy: 0.858\n",
      "macro f1: 0.602\n",
      "score: 0.780\n",
      "--------------------------------------------------\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=31, objective=None, random_state=42,\n",
      "        reg_alpha=0.0, reg_lambda=0.0, silent=False, subsample=1.0,\n",
      "        subsample_for_bin=200000, subsample_freq=1)\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.54      0.61       762\n",
      "          1       0.52      0.17      0.25       162\n",
      "          2       0.79      0.87      0.83      1800\n",
      "          3       0.98      0.99      0.99      6898\n",
      "\n",
      "avg / total       0.91      0.92      0.91      9622\n",
      "\n",
      "accuracy: 0.919\n",
      "macro f1: 0.668\n",
      "score: 0.867\n"
     ]
    }
   ],
   "source": [
    "clfs = [RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1, verbose=10, class_weight='balanced')]\n",
    "clfs += [LGBMClassifier(n_estimators=100, learning_rate=0.1, silent=False, random_state=42)]\n",
    "\n",
    "for clf in clfs:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    \n",
    "    print('-' * 50)\n",
    "    print(clf)\n",
    "    print('classification report:')\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print('accuracy: %.3f' % accuracy_score(y_val, y_pred))\n",
    "    print('macro f1: %.3f' % f1_score(y_val, y_pred, average='macro'))\n",
    "    print('score: %.3f' % (get_score(y_val, y_pred) / get_score(y_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.46      0.47      1903\n",
      "          1       0.43      0.00      0.01       697\n",
      "          2       0.74      0.73      0.73      4464\n",
      "          3       0.94      0.99      0.96     18349\n",
      "\n",
      "avg / total       0.86      0.88      0.86     25413\n",
      "\n",
      "accuracy: 0.875\n",
      "macro fscore: 0.544\n",
      "score: 0.781\n",
      "--------------------------------------------------\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.35      0.43      1903\n",
      "          1       0.00      0.00      0.00       697\n",
      "          2       0.75      0.73      0.74      4464\n",
      "          3       0.92      1.00      0.95     18349\n",
      "\n",
      "avg / total       0.84      0.87      0.85     25413\n",
      "\n",
      "accuracy: 0.872\n",
      "macro fscore: 0.530\n",
      "score: 0.759\n",
      "--------------------------------------------------\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.12      0.56      0.20      1903\n",
      "          1       0.06      0.10      0.07       697\n",
      "          2       0.29      0.31      0.30      4464\n",
      "          3       0.80      0.45      0.57     18349\n",
      "\n",
      "avg / total       0.64      0.42      0.48     25413\n",
      "\n",
      "accuracy: 0.422\n",
      "macro fscore: 0.285\n",
      "score: 0.445\n",
      "--------------------------------------------------\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 4), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=10, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.42      0.41      1903\n",
      "          1       0.23      0.00      0.01       697\n",
      "          2       0.64      0.68      0.66      4464\n",
      "          3       0.92      0.94      0.93     18349\n",
      "\n",
      "avg / total       0.82      0.83      0.82     25413\n",
      "\n",
      "accuracy: 0.830\n",
      "macro fscore: 0.503\n",
      "score: 0.738\n"
     ]
    }
   ],
   "source": [
    "clfs = [LinearSVC(), LogisticRegression(), MultinomialNB(), MLPClassifier(hidden_layer_sizes=(100, 4), early_stopping=True, max_iter=10)]\n",
    "for clf in clfs:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print('-' * 50)\n",
    "    print(clf)\n",
    "    print('classification report: ')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print('macro fscore: %.3f' % f1_score(y_test, y_pred, average='macro'))\n",
    "    print('score: %.3f' % (get_score(y_test, y_pred) / get_score(y_test, y_test)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add RandomForest and LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50building tree 3 of 50building tree 2 of 50building tree 4 of 50\n",
      "\n",
      "\n",
      "\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   15.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   25.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   36.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   51.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
      "            oob_score=False, random_state=42, verbose=10, warm_start=False)\n",
      "classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.27      0.35      1903\n",
      "          1       0.00      0.00      0.00       697\n",
      "          2       0.69      0.50      0.58      4464\n",
      "          3       0.85      0.98      0.91     18349\n",
      "\n",
      "avg / total       0.77      0.81      0.78     25413\n",
      "\n",
      "accuracy: 0.813\n",
      "macro fscore: 0.461\n",
      "score: 0.644\n",
      "--------------------------------------------------\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=-1, num_leaves=31, objective=None, random_state=42,\n",
      "        reg_alpha=0.0, reg_lambda=0.0, silent=False, subsample=1.0,\n",
      "        subsample_for_bin=200000, subsample_freq=1)\n",
      "classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.48      0.51      1903\n",
      "          1       0.40      0.00      0.01       697\n",
      "          2       0.73      0.79      0.76      4464\n",
      "          3       0.96      0.99      0.97     18349\n",
      "\n",
      "avg / total       0.87      0.89      0.87     25413\n",
      "\n",
      "accuracy: 0.888\n",
      "macro fscore: 0.562\n",
      "score: 0.811\n"
     ]
    }
   ],
   "source": [
    "clfs = [RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1, verbose=10, class_weight='balanced')]\n",
    "clfs += [LGBMClassifier(n_estimators=100, learning_rate=0.1, silent=False, random_state=42)]\n",
    "\n",
    "for clf in clfs:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print('-' * 50)\n",
    "    print(clf)\n",
    "    print('classification report: ')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print('macro fscore: %.3f' % f1_score(y_test, y_pred, average='macro'))\n",
    "    print('score: %.3f' % (get_score(y_test, y_pred) / get_score(y_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
